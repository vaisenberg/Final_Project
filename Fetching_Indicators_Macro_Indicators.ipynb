{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFpwgg8GkXuz",
        "outputId": "e716acf5-e4d7-4add-efe9-fb13bd887a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data for indicators, commodities, and macro indicators...\n",
            "Fetching data for ICLN (Attempt 1)...\n",
            "Data for ICLN fetched successfully.\n",
            "Fetching data for PBW (Attempt 1)...\n",
            "Data for PBW fetched successfully.\n",
            "Fetching data for TAN (Attempt 1)...\n",
            "Data for TAN fetched successfully.\n",
            "Fetching data for XLE (Attempt 1)...\n",
            "Data for XLE fetched successfully.\n",
            "Fetching data for VDE (Attempt 1)...\n",
            "Data for VDE fetched successfully.\n",
            "Fetching data for SPY (Attempt 1)...\n",
            "Data for SPY fetched successfully.\n",
            "Fetching data for QQQ (Attempt 1)...\n",
            "Data for QQQ fetched successfully.\n",
            "Fetching data for VIX (Attempt 1)...\n",
            "Data for VIX fetched successfully.\n",
            "Fetching data for EEM (Attempt 1)...\n",
            "Data for EEM fetched successfully.\n",
            "Fetching data for LIT (Attempt 1)...\n",
            "Data for LIT fetched successfully.\n",
            "Fetching data for URA (Attempt 1)...\n",
            "Data for URA fetched successfully.\n",
            "Fetching data for HYG (Attempt 1)...\n",
            "Data for HYG fetched successfully.\n",
            "Fetching data for EURUSD=X (Attempt 1)...\n",
            "Data for EURUSD=X fetched successfully.\n",
            "Fetching data for GBPUSD=X (Attempt 1)...\n",
            "Data for GBPUSD=X fetched successfully.\n",
            "Fetching data for CL=F (Attempt 1)...\n",
            "Data for CL=F fetched successfully.\n",
            "Fetching data for NG=F (Attempt 1)...\n",
            "Data for NG=F fetched successfully.\n",
            "Fetching data for DXY (Attempt 1)...\n",
            "Data for DXY fetched successfully.\n",
            "Fetching data for GC=F (Attempt 1)...\n",
            "Data for GC=F fetched successfully.\n",
            "Fetching data for SI=F (Attempt 1)...\n",
            "Data for SI=F fetched successfully.\n",
            "Fetching data for ^IRX (Attempt 1)...\n",
            "Data for ^IRX fetched successfully.\n",
            "Fetching data for ^TNX (Attempt 1)...\n",
            "Data for ^TNX fetched successfully.\n",
            "Fetching data for ^TYX (Attempt 1)...\n",
            "Data for ^TYX fetched successfully.\n",
            "Fetching data for MSCI (Attempt 1)...\n",
            "Data for MSCI fetched successfully.\n",
            "Fetching data for ^FTSE (Attempt 1)...\n",
            "Data for ^FTSE fetched successfully.\n",
            "Fetching data for ^N225 (Attempt 1)...\n",
            "Data for ^N225 fetched successfully.\n",
            "Fetching data for BTC-USD (Attempt 1)...\n",
            "Data for BTC-USD fetched successfully.\n",
            "Fetching data for ETH-USD (Attempt 1)...\n",
            "Data for ETH-USD fetched successfully.\n",
            "Data saved as 'indicators_commodities_macro_data.csv'.\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Define the categories\n",
        "indicators = ['ICLN', 'PBW', 'TAN', 'XLE', 'VDE', 'SPY', 'QQQ', 'VIX', 'EEM', 'LIT', 'URA', 'HYG', 'EURUSD=X', 'GBPUSD=X']\n",
        "commodities = ['CL=F', 'NG=F', 'DXY', 'GC=F', 'SI=F']  # Crude oil, natural gas, USD index, gold, silver\n",
        "macro_indicators = ['^IRX', '^TNX', '^TYX', 'MSCI', '^FTSE', '^N225', 'BTC-USD', 'ETH-USD']  # Treasury yields, MSCI, global indices, crypto\n",
        "\n",
        "# Combine all symbols\n",
        "all_assets = indicators + commodities + macro_indicators\n",
        "\n",
        "# Function to fetch data with retries\n",
        "def fetch_data(assets, start, end, retries=3):\n",
        "    valid_data = []\n",
        "    invalid_assets = {}\n",
        "\n",
        "    for asset in assets:\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                print(f\"Fetching data for {asset} (Attempt {attempt + 1})...\")\n",
        "                data = yf.download(asset, start=start, end=end, progress=False)\n",
        "                if not data.empty:\n",
        "                    print(f\"Data for {asset} fetched successfully.\")\n",
        "                    data['Asset'] = asset\n",
        "                    valid_data.append(data)\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"Data for {asset} is empty. Retrying...\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching data for {asset}: {e}\")\n",
        "                if attempt == retries - 1:\n",
        "                    invalid_assets[asset] = str(e)\n",
        "                time.sleep(2)  # Wait before retrying\n",
        "\n",
        "    return valid_data, invalid_assets\n",
        "\n",
        "# Fetch all data\n",
        "print(\"Fetching data for indicators, commodities, and macro indicators...\")\n",
        "all_data, invalid_assets = fetch_data(all_assets, start=\"2015-01-01\", end=\"2025-01-01\")\n",
        "\n",
        "# Save valid data\n",
        "if all_data:\n",
        "    combined_data = pd.concat(all_data).reset_index()\n",
        "    combined_data.to_csv(\"indicators_commodities_macro_data.csv\", index=False)\n",
        "    print(\"Data saved as 'indicators_commodities_macro_data.csv'.\")\n",
        "else:\n",
        "    print(\"No valid data fetched.\")\n",
        "\n",
        "# Log invalid fetches\n",
        "if invalid_assets:\n",
        "    with open(\"invalid_indicators_log.txt\", \"w\") as log_file:\n",
        "        log_file.write(\"Invalid Indicators, Commodities, and Macro Indicators:\\n\")\n",
        "        for asset, reason in invalid_assets.items():\n",
        "            log_file.write(f\"{asset}: {reason}\\n\")\n",
        "    print(\"Invalid data logged.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning fetched data\n",
        "print(\"Cleaning fetched data...\")\n",
        "file_path = \"indicators_commodities_macro_data.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Drop metadata row\n",
        "data = data.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "# Step 2: Clean column names\n",
        "data.columns = [col.replace('.', '_') for col in data.columns]\n",
        "\n",
        "# Step 3: Restructure dataset\n",
        "assets = indicators + commodities + macro_indicators\n",
        "long_data = pd.DataFrame()\n",
        "\n",
        "# Process the first asset (base columns)\n",
        "base_columns = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
        "temp = data[['Date'] + base_columns].copy()\n",
        "temp.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
        "temp['Asset'] = assets[0]  # Assuming the first asset\n",
        "temp['Type'] = 'Indicator'\n",
        "long_data = pd.concat([long_data, temp], ignore_index=True)\n",
        "\n",
        "# Process other assets\n",
        "for i, asset in enumerate(assets[1:]):\n",
        "    asset_columns = [f'{col}_{i+1}' for col in base_columns if f'{col}_{i+1}' in data.columns]\n",
        "    if asset_columns:\n",
        "        temp = data[['Date'] + asset_columns].copy()\n",
        "        temp.columns = ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
        "        temp['Asset'] = asset\n",
        "        temp['Type'] = 'Indicator'\n",
        "        long_data = pd.concat([long_data, temp], ignore_index=True)\n",
        "\n",
        "# Step 4: Convert data types\n",
        "long_data['Date'] = pd.to_datetime(long_data['Date'], errors='coerce')\n",
        "numeric_cols = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
        "for col in numeric_cols:\n",
        "    long_data[col] = pd.to_numeric(long_data[col], errors='coerce')\n",
        "\n",
        "# Step 5: Filter rows with missing numeric data\n",
        "long_data = long_data.dropna(subset=numeric_cols, how='all')\n",
        "\n",
        "# Step 6: Save cleaned dataset\n",
        "output_path = \"final_indicators_commodities_macro_data.csv\"\n",
        "long_data.to_csv(output_path, index=False)\n",
        "print(f\"Final cleaned data saved to {output_path}\")\n",
        "\n",
        "# Display dataset summary\n",
        "print(long_data.info())\n",
        "print(long_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oXZ-XRxk82g",
        "outputId": "edea4468-e738-4b57-94ab-be5e486717d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning fetched data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-66f132f44fb3>:4: DtypeWarning: Columns (1,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final cleaned data saved to final_indicators_commodities_macro_data.csv\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 66119 entries, 0 to 1785212\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   Date    66119 non-null  datetime64[ns]\n",
            " 1   Close   66119 non-null  float64       \n",
            " 2   High    66119 non-null  float64       \n",
            " 3   Low     66119 non-null  float64       \n",
            " 4   Open    66119 non-null  float64       \n",
            " 5   Volume  66119 non-null  float64       \n",
            " 6   Asset   66119 non-null  object        \n",
            " 7   Type    66119 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(5), object(2)\n",
            "memory usage: 4.5+ MB\n",
            "None\n",
            "        Date     Close      High       Low      Open    Volume Asset  \\\n",
            "0 2015-01-02  8.124761  8.199759  8.033097  8.199759   52200.0  ICLN   \n",
            "1 2015-01-05  7.949766  8.166426  7.891434  8.166426   34500.0  ICLN   \n",
            "2 2015-01-06  7.933097  8.033094  7.874765  7.999761   18100.0  ICLN   \n",
            "3 2015-01-07  8.008096  8.058095  7.933099  7.933099  221700.0  ICLN   \n",
            "4 2015-01-08  8.199759  8.208093  8.058097  8.058097   61900.0  ICLN   \n",
            "\n",
            "        Type  \n",
            "0  Indicator  \n",
            "1  Indicator  \n",
            "2  Indicator  \n",
            "3  Indicator  \n",
            "4  Indicator  \n"
          ]
        }
      ]
    }
  ]
}